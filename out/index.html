<!DOCTYPE html><!--yFpf8o_p04QO1KznxKOpg--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/Portfolio/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/Portfolio/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/Portfolio/_next/static/chunks/667764c0354a4aa9.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Portfolio/_next/static/chunks/4b9eae0c8dc7e975.js"/><script src="/Portfolio/_next/static/chunks/f2f58a7e93290fbb.js" async=""></script><script src="/Portfolio/_next/static/chunks/66a6f523333d418b.js" async=""></script><script src="/Portfolio/_next/static/chunks/turbopack-1aa5c7a68676a3af.js" async=""></script><script src="/Portfolio/_next/static/chunks/2f236954d6a65e12.js" async=""></script><script src="/Portfolio/_next/static/chunks/f813fde7a26bc4e5.js" async=""></script><meta name="next-size-adjust" content=""/><title>Portfolio | Robotics &amp; Computer Vision Engineer</title><meta name="description" content="Personal portfolio of a Robotics &amp; Computer Vision engineer specializing in perception systems, deep learning, and camera calibration."/><script src="/Portfolio/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="inter_8f1c4a24-module__nx7jFG__variable jetbrains_mono_4282af4f-module__TNdyLG__variable font-sans antialiased"><div hidden=""><!--$--><!--/$--></div><header class="fixed top-0 left-0 right-0 z-50 bg-background/80 backdrop-blur-md border-b border-border"><nav class="mx-auto flex max-w-5xl items-center justify-between px-6 py-4"><a href="#" class="text-lg font-semibold tracking-tight text-foreground">&lt;CV /&gt;</a><ul class="hidden items-center gap-8 md:flex"><li><a href="#about" class="text-sm text-muted-foreground transition-colors hover:text-primary">About</a></li><li><a href="#projects" class="text-sm text-muted-foreground transition-colors hover:text-primary">Projects</a></li><li><a href="#teaching" class="text-sm text-muted-foreground transition-colors hover:text-primary">Teaching</a></li><li><a href="#blog" class="text-sm text-muted-foreground transition-colors hover:text-primary">Blog</a></li><li><a href="#contact" class="text-sm text-muted-foreground transition-colors hover:text-primary">Contact</a></li></ul><button class="text-foreground md:hidden" aria-label="Open menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg></button></nav></header><main><section class="relative flex min-h-screen items-center justify-center px-6 pt-20"><div class="mx-auto max-w-3xl text-center"><p class="mb-4 font-mono text-sm tracking-widest text-primary uppercase">Hello, I am</p><h1 class="text-balance text-4xl font-bold leading-tight tracking-tight text-foreground sm:text-5xl lg:text-6xl">Sarvesh Angadi</h1><h2 class="mt-4 text-xl font-medium text-foreground/80 sm:text-2xl">Robotics &amp; Computer Vision Engineer</h2><p class="mt-3 font-mono text-sm tracking-wide text-muted-foreground">Perception · Learning Systems · Teaching</p><div class="mt-8 flex items-center justify-center gap-4"><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 rounded-lg bg-foreground px-5 py-2.5 text-sm font-medium text-background transition-opacity hover:opacity-90"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>GitHub</a><a href="https://linkedin.com" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 rounded-lg border border-border px-5 py-2.5 text-sm font-medium text-foreground transition-colors hover:bg-muted"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-4 w-4" aria-hidden="true"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg>LinkedIn</a></div></div><a href="#about" class="absolute bottom-10 left-1/2 -translate-x-1/2 animate-bounce text-muted-foreground" aria-label="Scroll to about section"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-down h-5 w-5" aria-hidden="true"><path d="M12 5v14"></path><path d="m19 12-7 7-7-7"></path></svg></a></section><section id="about" class="px-6 py-24"><div class="mx-auto max-w-5xl"><div class="flex items-center gap-3"><span class="h-px w-8 bg-primary"></span><span class="font-mono text-sm tracking-widest text-primary uppercase">About</span></div><h2 class="mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl">Building intelligent machines that see and understand</h2><p class="mt-6 max-w-2xl text-base leading-relaxed text-muted-foreground">I am a robotics engineer with a focus on computer vision and perception. My work sits at the intersection of classical geometry-based methods and modern deep learning, enabling autonomous systems to interpret complex visual scenes. I have contributed to research in camera calibration, visual SLAM, and learning-based perception deployed on real-world robotic platforms.</p><div class="mt-16 grid gap-8 sm:grid-cols-2"><div class="group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30"><div class="mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-eye h-5 w-5" aria-hidden="true"><path d="M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0"></path><circle cx="12" cy="12" r="3"></circle></svg></div><h3 class="text-base font-semibold text-card-foreground">Perception Systems</h3><p class="mt-2 text-sm leading-relaxed text-muted-foreground">Building real-time 3D perception pipelines for autonomous robots using LiDAR, stereo vision, and sensor fusion.</p></div><div class="group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30"><div class="mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-camera h-5 w-5" aria-hidden="true"><path d="M13.997 4a2 2 0 0 1 1.76 1.05l.486.9A2 2 0 0 0 18.003 7H20a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V9a2 2 0 0 1 2-2h1.997a2 2 0 0 0 1.759-1.048l.489-.904A2 2 0 0 1 10.004 4z"></path><circle cx="12" cy="13" r="3"></circle></svg></div><h3 class="text-base font-semibold text-card-foreground">Camera Calibration</h3><p class="mt-2 text-sm leading-relaxed text-muted-foreground">Developing robust multi-camera calibration frameworks for accurate metric reconstruction in industrial environments.</p></div><div class="group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30"><div class="mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-brain h-5 w-5" aria-hidden="true"><path d="M12 18V5"></path><path d="M15 13a4.17 4.17 0 0 1-3-4 4.17 4.17 0 0 1-3 4"></path><path d="M17.598 6.5A3 3 0 1 0 12 5a3 3 0 1 0-5.598 1.5"></path><path d="M17.997 5.125a4 4 0 0 1 2.526 5.77"></path><path d="M18 18a4 4 0 0 0 2-7.464"></path><path d="M19.967 17.483A4 4 0 1 1 12 18a4 4 0 1 1-7.967-.517"></path><path d="M6 18a4 4 0 0 1-2-7.464"></path><path d="M6.003 5.125a4 4 0 0 0-2.526 5.77"></path></svg></div><h3 class="text-base font-semibold text-card-foreground">Deep Learning</h3><p class="mt-2 text-sm leading-relaxed text-muted-foreground">Designing and training CNNs and transformers for object detection, segmentation, and visual place recognition.</p></div><div class="group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30"><div class="mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-box h-5 w-5" aria-hidden="true"><path d="M21 8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16Z"></path><path d="m3.3 7 8.7 5 8.7-5"></path><path d="M12 22V12"></path></svg></div><h3 class="text-base font-semibold text-card-foreground">GenAI-Powered 3D Perception</h3><p class="mt-2 text-sm leading-relaxed text-muted-foreground">Applying generative models and Gaussian Splatting to enable scalable 3D scene reconstruction, immersive mapping, and real-time spatial intelligence for robotics and AR/VR applications.</p></div></div></div></section><section id="projects" class="bg-muted/50 px-6 py-24"><div class="mx-auto max-w-5xl"><div class="flex items-center gap-3"><span class="h-px w-8 bg-primary"></span><span class="font-mono text-sm tracking-widest text-primary uppercase">Projects</span></div><h2 class="mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl">Selected work</h2><p class="mt-4 max-w-xl text-base text-muted-foreground">Open-source projects and research implementations spanning perception, calibration, and deep learning for robotics.</p><div class="mt-12 grid gap-6 md:grid-cols-2 lg:grid-cols-3"><article class="group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm"><div class="mb-3 flex items-center justify-between"><h3 class="text-base font-semibold text-card-foreground">Vision-Conditioned Trajectory Generation with Flow Matching</h3><a href="https://github.com/SarveshAngadi09/TrajectoryGenerationFlowmatching" target="_blank" rel="noopener noreferrer" class="text-muted-foreground transition-colors hover:text-primary" aria-label="View Vision-Conditioned Trajectory Generation with Flow Matching on GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><p class="flex-1 text-sm leading-relaxed text-muted-foreground">Implementing conditional and mean flow matching models for vision-conditioned robotic trajectory generation on the PushT dataset.</p><div class="mt-4 flex flex-wrap gap-2"><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Pytorch</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Path Planning</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">GenAI</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Robotics</span></div></article><article class="group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm"><div class="mb-3 flex items-center justify-between"><h3 class="text-base font-semibold text-card-foreground">Adversarial Attacks in Neural Networks</h3><a href="https://github.com/SarveshAngadi09/DLadversarialattack" target="_blank" rel="noopener noreferrer" class="text-muted-foreground transition-colors hover:text-primary" aria-label="View Adversarial Attacks in Neural Networks on GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><p class="flex-1 text-sm leading-relaxed text-muted-foreground">Implementation and analysis of adversarial attack strategies and defense mechanisms to study robustness in deep neural networks.</p><div class="mt-4 flex flex-wrap gap-2"><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Python</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Pytorch</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">OpenCV</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Neural Networks</span></div></article><article class="group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm"><div class="mb-3 flex items-center justify-between"><h3 class="text-base font-semibold text-card-foreground">Mapping facial features and hand gestures</h3><a href="https://github.com/SarveshAngadi09/Face-Hand-Interaction-Computer-vision" target="_blank" rel="noopener noreferrer" class="text-muted-foreground transition-colors hover:text-primary" aria-label="View Mapping facial features and hand gestures on GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><p class="flex-1 text-sm leading-relaxed text-muted-foreground">Implementation of face and palm detection using mediapipe and openCV</p><div class="mt-4 flex flex-wrap gap-2"><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">Python</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">mediapipe</span><span class="rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary">OpenCV</span></div></article></div><div class="mt-10 text-center"><a href="https://github.com/SarveshAngadi09" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 text-sm font-medium text-primary transition-colors hover:text-primary/80">View all projects on GitHub<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3.5 w-3.5" aria-hidden="true"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></section><section id="teaching" class="px-6 py-24"><div class="mx-auto max-w-5xl"><div class="flex items-center gap-3"><span class="h-px w-8 bg-primary"></span><span class="font-mono text-sm tracking-widest text-primary uppercase">Teaching &amp; Talks</span></div><h2 class="mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl">Workshops &amp; presentations</h2><p class="mt-4 max-w-xl text-base text-muted-foreground">Sharing knowledge through workshops, talks, and seminars on computer vision, robotics, and deep learning.</p><div class="mt-12 space-y-4"><div class="group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30"><div class="flex flex-col gap-4 sm:flex-row sm:items-start sm:justify-between"><div class="flex-1"><div class="mb-2 flex items-center gap-3"><span class="inline-flex items-center gap-1.5 rounded-md bg-primary/10 px-2.5 py-0.5 text-xs font-medium text-primary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-presentation h-3 w-3" aria-hidden="true"><path d="M2 3h20"></path><path d="M21 3v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V3"></path><path d="m7 21 5-5 5 5"></path></svg>Teaching</span><span class="inline-flex items-center gap-1.5 text-xs text-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar h-3 w-3" aria-hidden="true"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>Feb 2026</span></div><h3 class="text-base font-semibold text-card-foreground">Vision-Driven Robotics: Theory to Practice</h3><p class="mt-1 text-sm text-muted-foreground">Discord</p><p class="mt-2 text-sm leading-relaxed text-muted-foreground/80">I conduct independent sessions on Computer Vision and Robotics fundamentals for students and early learners. The sessions focus on building strong intuition behind core concepts such as camera calibration, multi-view geometry, deep learning for perception, and generative models for robotics. My goal is to bridge theory and implementation — breaking down complex ideas into clear mathematical reasoning and practical code examples.</p><a href="https://github.com/SarveshAngadi09/Robotics-CV" target="_blank" rel="noopener noreferrer" class="mt-4 inline-flex items-center gap-2 text-sm font-medium text-primary transition-colors hover:underline"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>View Materials on GitHub</a></div></div></div></div></div></section><section id="blog" class="bg-muted/50 px-6 py-24"><div class="mx-auto max-w-5xl"><div class="flex items-center gap-3"><span class="h-px w-8 bg-primary"></span><span class="font-mono text-sm tracking-widest text-primary uppercase">Blog</span></div><h2 class="mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl">Recent writing</h2><p class="mt-4 max-w-xl text-base text-muted-foreground">Technical notes and tutorials on topics I find interesting.</p><div class="mt-12 grid gap-6 md:grid-cols-3"><a href="https://github.com/SarveshAngadi09/Robotics-CV/tree/main/NormalizingFlows" target="_blank" rel="noopener noreferrer" class="group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm"><div class="mb-3 flex items-center gap-3"><span class="rounded-md bg-primary/10 px-2.5 py-0.5 text-xs font-medium text-primary">Generative AI</span><span class="text-xs text-muted-foreground">Feb 2026</span></div><h3 class="text-base font-semibold leading-snug text-card-foreground">Normalizing Flows: Density Estimation via Change of Variables</h3><p class="mt-2 flex-1 text-sm leading-relaxed text-muted-foreground">An intuitive and mathematical introduction to normalizing flows, explaining density estimation through invertible transformations and the change-of-variables formula.</p><div class="mt-4 flex items-center justify-between"><span class="font-mono text-xs text-muted-foreground">8 min read</span><span class="inline-flex items-center gap-1 text-sm font-medium text-primary opacity-0 transition-opacity group-hover:opacity-100">Read<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-3.5 w-3.5" aria-hidden="true"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></span></div></a><a href="https://github.com/SarveshAngadi09/Robotics-CV/tree/main/Calibration" target="_blank" rel="noopener noreferrer" class="group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm"><div class="mb-3 flex items-center gap-3"><span class="rounded-md bg-primary/10 px-2.5 py-0.5 text-xs font-medium text-primary">Calibration</span><span class="text-xs text-muted-foreground">Feb 2026</span></div><h3 class="text-base font-semibold leading-snug text-card-foreground">Basics of Camera Calibration</h3><p class="mt-2 flex-1 text-sm leading-relaxed text-muted-foreground">An intuitive and mathematical introduction to intrinsic camera calibration, covering focal length, principal point estimation, and lens distortion modeling for accurate vision-based perception.</p><div class="mt-4 flex items-center justify-between"><span class="font-mono text-xs text-muted-foreground">6 min read</span><span class="inline-flex items-center gap-1 text-sm font-medium text-primary opacity-0 transition-opacity group-hover:opacity-100">Read<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-3.5 w-3.5" aria-hidden="true"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></span></div></a></div></div></section><section id="contact" class="px-6 py-24"><div class="mx-auto max-w-5xl"><div class="flex items-center gap-3"><span class="h-px w-8 bg-primary"></span><span class="font-mono text-sm tracking-widest text-primary uppercase">Contact</span></div><h2 class="mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl">Let&#x27;s connect</h2><p class="mt-4 max-w-xl text-base text-muted-foreground">Interested in hiring me, collaboration, research opportunities, or just want to say hello? I&#x27;d love to hear from you.</p><div class="mt-12 flex flex-col gap-8 sm:flex-row sm:items-start sm:gap-16"><div><h3 class="text-sm font-semibold uppercase tracking-wider text-foreground">Email</h3><a href="mailto:sarvesh.angadi1997@gmail.com" class="mt-2 inline-flex items-center gap-2 text-base text-primary transition-colors hover:text-primary/80"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-4 w-4" aria-hidden="true"><path d="m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"></path><rect x="2" y="4" width="20" height="16" rx="2"></rect></svg>sarvesh.angadi1997@gmail.com</a></div><div><h3 class="text-sm font-semibold uppercase tracking-wider text-foreground">Social</h3><ul class="mt-2 flex items-center gap-4"><li><a href="https://github.com/SarveshAngadi09" target="_blank" rel="noopener noreferrer" class="inline-flex h-10 w-10 items-center justify-center rounded-lg border border-border text-muted-foreground transition-colors hover:border-primary/30 hover:text-primary" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></li><li><a href="https://www.linkedin.com/in/sarvesh-angadi-067375154/" target="_blank" rel="noopener noreferrer" class="inline-flex h-10 w-10 items-center justify-center rounded-lg border border-border text-muted-foreground transition-colors hover:border-primary/30 hover:text-primary" aria-label="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-4 w-4" aria-hidden="true"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a></li></ul></div></div></div></section></main><footer class="border-t border-border px-6 py-8"><div class="mx-auto flex max-w-5xl flex-col items-center justify-between gap-4 sm:flex-row"><p class="text-sm text-muted-foreground">© 2026 Sarvesh Angadi. All rights reserved.</p><p class="font-mono text-xs text-muted-foreground/60">Latent space</p></div></footer><!--$--><!--/$--><script src="/Portfolio/_next/static/chunks/4b9eae0c8dc7e975.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/Portfolio/_next/static/chunks/2f236954d6a65e12.js\"],\"default\"]\n3:I[37457,[\"/Portfolio/_next/static/chunks/2f236954d6a65e12.js\"],\"default\"]\n4:I[63780,[\"/Portfolio/_next/static/chunks/f813fde7a26bc4e5.js\"],\"Navbar\"]\n11:I[68027,[\"/Portfolio/_next/static/chunks/2f236954d6a65e12.js\"],\"default\"]\n:HL[\"/Portfolio/_next/static/chunks/667764c0354a4aa9.css\",\"style\"]\n:HL[\"/Portfolio/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/Portfolio/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"yFpf8o_p04QO1KznxKOpg\",\"c\":[\"\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/667764c0354a4aa9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"inter_8f1c4a24-module__nx7jFG__variable jetbrains_mono_4282af4f-module__TNdyLG__variable font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"$L4\",null,{}],[\"$\",\"main\",null,{\"children\":[[\"$\",\"section\",null,{\"className\":\"relative flex min-h-screen items-center justify-center px-6 pt-20\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-3xl text-center\",\"children\":[[\"$\",\"p\",null,{\"className\":\"mb-4 font-mono text-sm tracking-widest text-primary uppercase\",\"children\":\"Hello, I am\"}],[\"$\",\"h1\",null,{\"className\":\"text-balance text-4xl font-bold leading-tight tracking-tight text-foreground sm:text-5xl lg:text-6xl\",\"children\":\"Sarvesh Angadi\"}],[\"$\",\"h2\",null,{\"className\":\"mt-4 text-xl font-medium text-foreground/80 sm:text-2xl\",\"children\":\"Robotics \u0026 Computer Vision Engineer\"}],[\"$\",\"p\",null,{\"className\":\"mt-3 font-mono text-sm tracking-wide text-muted-foreground\",\"children\":\"Perception · Learning Systems · Teaching\"}],[\"$\",\"div\",null,{\"className\":\"mt-8 flex items-center justify-center gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://github.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-2 rounded-lg bg-foreground px-5 py-2.5 text-sm font-medium text-background transition-opacity hover:opacity-90\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}],\"GitHub\"]}],[\"$\",\"a\",null,{\"href\":\"https://linkedin.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-2 rounded-lg border border-border px-5 py-2.5 text-sm font-medium text-foreground transition-colors hover:bg-muted\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],\"$L5\",\"$L6\",\"$undefined\"]}],\"LinkedIn\"]}]]}]]}],\"$L7\"]}],\"$L8\",\"$L9\",\"$La\",\"$Lb\",\"$Lc\"]}],\"$Ld\"],[\"$Le\"],\"$Lf\"]}],{},null,false,false]},null,false,false],\"$L10\",false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"23:I[97367,[\"/Portfolio/_next/static/chunks/2f236954d6a65e12.js\"],\"OutletBoundary\"]\n24:\"$Sreact.suspense\"\n26:I[97367,[\"/Portfolio/_next/static/chunks/2f236954d6a65e12.js\"],\"ViewportBoundary\"]\n28:I[97367,[\"/Portfolio/_next/static/chunks/2f236954d6a65e12.js\"],\"MetadataBoundary\"]\n5:[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}]\n6:[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}]\n7:[\"$\",\"a\",null,{\"href\":\"#about\",\"className\":\"absolute bottom-10 left-1/2 -translate-x-1/2 animate-bounce text-muted-foreground\",\"aria-label\":\"Scroll to about section\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-down h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"s699le\",{\"d\":\"M12 5v14\"}],[\"$\",\"path\",\"1idqje\",{\"d\":\"m19 12-7 7-7-7\"}],\"$undefined\"]}]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"section\",null,{\"id\":\"about\",\"className\":\"px-6 py-24\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-5xl\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"h-px w-8 bg-primary\"}],[\"$\",\"span\",null,{\"className\":\"font-mono text-sm tracking-widest text-primary uppercase\",\"children\":\"About\"}]]}],[\"$\",\"h2\",null,{\"className\":\"mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl\",\"children\":\"Building intelligent machines that see and understand\"}],[\"$\",\"p\",null,{\"className\":\"mt-6 max-w-2xl text-base leading-relaxed text-muted-foreground\",\"children\":\"I am a robotics engineer with a focus on computer vision and perception. My work sits at the intersection of classical geometry-based methods and modern deep learning, enabling autonomous systems to interpret complex visual scenes. I have contributed to research in camera calibration, visual SLAM, and learning-based perception deployed on real-world robotic platforms.\"}],[\"$\",\"div\",null,{\"className\":\"mt-16 grid gap-8 sm:grid-cols-2\",\"children\":[[\"$\",\"div\",\"Perception Systems\",{\"className\":\"group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-eye h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1nclc0\",{\"d\":\"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0\"}],[\"$\",\"circle\",\"1v7zrd\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"3\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Perception Systems\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Building real-time 3D perception pipelines for autonomous robots using LiDAR, stereo vision, and sensor fusion.\"}]]}],[\"$\",\"div\",\"Camera Calibration\",{\"className\":\"group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-camera h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"18u6gg\",{\"d\":\"M13.997 4a2 2 0 0 1 1.76 1.05l.486.9A2 2 0 0 0 18.003 7H20a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V9a2 2 0 0 1 2-2h1.997a2 2 0 0 0 1.759-1.048l.489-.904A2 2 0 0 1 10.004 4z\"}],[\"$\",\"circle\",\"1vg3eu\",{\"cx\":\"12\",\"cy\":\"13\",\"r\":\"3\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Camera Calibration\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Developing robust multi-camera calibration frameworks for accurate metric reconstruction in industrial environments.\"}]]}],[\"$\",\"div\",\"Deep Learning\",{\"className\":\"group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-brain h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"adv99a\",{\"d\":\"M12 18V5\"}],[\"$\",\"path\",\"1e3is1\",{\"d\":\"M15 13a4.17 4.17 0 0 1-3-4 4.17 4.17 0 0 1-3 4\"}],\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\",\"$undefined\"]}]}],\"$L18\",\"$L19\"]}],\"$L1a\"]}]]}]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"section\",null,{\"id\":\"projects\",\"className\":\"bg-muted/50 px-6 py-24\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-5xl\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"h-px w-8 bg-primary\"}],[\"$\",\"span\",null,{\"className\":\"font-mono text-sm tracking-widest text-primary uppercase\",\"children\":\"Projects\"}]]}],[\"$\",\"h2\",null,{\"className\":\"mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl\",\"children\":\"Selected work\"}],[\"$\",\"p\",null,{\"className\":\"mt-4 max-w-xl text-base text-muted-foreground\",\"children\":\"Open-source projects and research implementations spanning perception, calibration, and deep learning for robotics.\"}],[\"$\",\"div\",null,{\"className\":\"mt-12 grid gap-6 md:grid-cols-2 lg:grid-cols-3\",\"children\":[[\"$\",\"article\",\"Vision-Conditioned Trajectory Generation with Flow Matching\",{\"className\":\"group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 flex items-center justify-between\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Vision-Conditioned Trajectory Generation with Flow Matching\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/SarveshAngadi09/TrajectoryGenerationFlowmatching\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-muted-foreground transition-colors hover:text-primary\",\"aria-label\":\"View Vision-Conditioned Trajectory Generation with Flow Matching on GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}]]}],[\"$\",\"p\",null,{\"className\":\"flex-1 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Implementing conditional and mean flow matching models for vision-conditioned robotic trajectory generation on the PushT dataset.\"}],[\"$\",\"div\",null,{\"className\":\"mt-4 flex flex-wrap gap-2\",\"children\":[[\"$\",\"span\",\"Pytorch\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Pytorch\"}],[\"$\",\"span\",\"Path Planning\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Path Planning\"}],[\"$\",\"span\",\"GenAI\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"GenAI\"}],[\"$\",\"span\",\"Robotics\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Robotics\"}]]}]]}],[\"$\",\"article\",\"Adversarial Attacks in Neural Networks\",{\"className\":\"group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 flex items-center justify-between\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Adversarial Attacks in Neural Networks\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/SarveshAngadi09/DLadversarialattack\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-muted-foreground transition-colors hover:text-primary\",\"aria-label\":\"View Adversarial Attacks in Neural Networks on GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[\"$L1b\",\"$L1c\",\"$undefined\"]}]}]]}],\"$L1d\",\"$L1e\"]}],\"$L1f\"]}],\"$L20\"]}]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"section\",null,{\"id\":\"teaching\",\"className\":\"px-6 py-24\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-5xl\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"h-px w-8 bg-primary\"}],[\"$\",\"span\",null,{\"className\":\"font-mono text-sm tracking-widest text-primary uppercase\",\"children\":\"Teaching \u0026 Talks\"}]]}],[\"$\",\"h2\",null,{\"className\":\"mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl\",\"children\":\"Workshops \u0026 presentations\"}],[\"$\",\"p\",null,{\"className\":\"mt-4 max-w-xl text-base text-muted-foreground\",\"children\":\"Sharing knowledge through workshops, talks, and seminars on computer vision, robotics, and deep learning.\"}],[\"$\",\"div\",null,{\"className\":\"mt-12 space-y-4\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-4 sm:flex-row sm:items-start sm:justify-between\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-2 flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"inline-flex items-center gap-1.5 rounded-md bg-primary/10 px-2.5 py-0.5 text-xs font-medium text-primary\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-presentation h-3 w-3\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"91anmk\",{\"d\":\"M2 3h20\"}],[\"$\",\"path\",\"2k9sn8\",{\"d\":\"M21 3v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V3\"}],[\"$\",\"path\",\"bip4we\",{\"d\":\"m7 21 5-5 5 5\"}],\"$undefined\"]}],\"Teaching\"]}],[\"$\",\"span\",null,{\"className\":\"inline-flex items-center gap-1.5 text-xs text-muted-foreground\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-calendar h-3 w-3\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1cmpym\",{\"d\":\"M8 2v4\"}],[\"$\",\"path\",\"4m81vk\",{\"d\":\"M16 2v4\"}],[\"$\",\"rect\",\"1hopcy\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"8toen8\",{\"d\":\"M3 10h18\"}],\"$undefined\"]}],\"Feb 2026\"]}]]}],[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Vision-Driven Robotics: Theory to Practice\"}],[\"$\",\"p\",null,{\"className\":\"mt-1 text-sm text-muted-foreground\",\"children\":\"Discord\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm leading-relaxed text-muted-foreground/80\",\"children\":\"I conduct independent sessions on Computer Vision and Robotics fundamentals for students and early learners. The sessions focus on building strong intuition behind core concepts such as camera calibration, multi-view geometry, deep learning for perception, and generative models for robotics. My goal is to bridge theory and implementation — breaking down complex ideas into clear mathematical reasoning and practical code examples.\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/SarveshAngadi09/Robotics-CV\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"mt-4 inline-flex items-center gap-2 text-sm font-medium text-primary transition-colors hover:underline\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}],\"View Materials on GitHub\"]}]]}]}]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"section\",null,{\"id\":\"blog\",\"className\":\"bg-muted/50 px-6 py-24\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-5xl\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"h-px w-8 bg-primary\"}],[\"$\",\"span\",null,{\"className\":\"font-mono text-sm tracking-widest text-primary uppercase\",\"children\":\"Blog\"}]]}],[\"$\",\"h2\",null,{\"className\":\"mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl\",\"children\":\"Recent writing\"}],[\"$\",\"p\",null,{\"className\":\"mt-4 max-w-xl text-base text-muted-foreground\",\"children\":\"Technical notes and tutorials on topics I find interesting.\"}],[\"$\",\"div\",null,{\"className\":\"mt-12 grid gap-6 md:grid-cols-3\",\"children\":[[\"$\",\"a\",\"Normalizing Flows: Density Estimation via Change of Variables\",{\"href\":\"https://github.com/SarveshAngadi09/Robotics-CV/tree/main/NormalizingFlows\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"rounded-md bg-primary/10 px-2.5 py-0.5 text-xs font-medium text-primary\",\"children\":\"Generative AI\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Feb 2026\"}]]}],[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold leading-snug text-card-foreground\",\"children\":\"Normalizing Flows: Density Estimation via Change of Variables\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 flex-1 text-sm leading-relaxed text-muted-foreground\",\"children\":\"An intuitive and mathematical introduction to normalizing flows, explaining density estimation through invertible transformations and the change-of-variables formula.\"}],[\"$\",\"div\",null,{\"className\":\"mt-4 flex items-center justify-between\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-mono text-xs text-muted-foreground\",\"children\":\"8 min read\"}],[\"$\",\"span\",null,{\"className\":\"inline-flex items-center gap-1 text-sm font-medium text-primary opacity-0 transition-opacity group-hover:opacity-100\",\"children\":[\"Read\",[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-right h-3.5 w-3.5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1ays0h\",{\"d\":\"M5 12h14\"}],[\"$\",\"path\",\"xquz4c\",{\"d\":\"m12 5 7 7-7 7\"}],\"$undefined\"]}]]}]]}]]}],[\"$\",\"a\",\"Basics of Camera Calibration\",{\"href\":\"https://github.com/SarveshAngadi09/Robotics-CV/tree/main/Calibration\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"rounded-md bg-primary/10 px-2.5 py-0.5 text-xs font-medium text-primary\",\"children\":\"Calibration\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Feb 2026\"}]]}],[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold leading-snug text-card-foreground\",\"children\":\"Basics of Camera Calibration\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 flex-1 text-sm leading-relaxed text-muted-foreground\",\"children\":\"An intuitive and mathematical introduction to intrinsic camera calibration, covering focal length, principal point estimation, and lens distortion modeling for accurate vision-based perception.\"}],[\"$\",\"div\",null,{\"className\":\"mt-4 flex items-center justify-between\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-mono text-xs text-muted-foreground\",\"children\":\"6 min read\"}],[\"$\",\"span\",null,{\"className\":\"inline-flex items-center gap-1 text-sm font-medium text-primary opacity-0 transition-opacity group-hover:opacity-100\",\"children\":[\"Read\",[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-right h-3.5 w-3.5\",\"aria-hidden\":\"true\",\"children\":[\"$L21\",\"$L22\",\"$undefined\"]}]]}]]}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"section\",null,{\"id\":\"contact\",\"className\":\"px-6 py-24\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-5xl\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"h-px w-8 bg-primary\"}],[\"$\",\"span\",null,{\"className\":\"font-mono text-sm tracking-widest text-primary uppercase\",\"children\":\"Contact\"}]]}],[\"$\",\"h2\",null,{\"className\":\"mt-2 text-3xl font-bold tracking-tight text-foreground sm:text-4xl\",\"children\":\"Let's connect\"}],[\"$\",\"p\",null,{\"className\":\"mt-4 max-w-xl text-base text-muted-foreground\",\"children\":\"Interested in hiring me, collaboration, research opportunities, or just want to say hello? I'd love to hear from you.\"}],[\"$\",\"div\",null,{\"className\":\"mt-12 flex flex-col gap-8 sm:flex-row sm:items-start sm:gap-16\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-sm font-semibold uppercase tracking-wider text-foreground\",\"children\":\"Email\"}],[\"$\",\"a\",null,{\"href\":\"mailto:sarvesh.angadi1997@gmail.com\",\"className\":\"mt-2 inline-flex items-center gap-2 text-base text-primary transition-colors hover:text-primary/80\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"132q7q\",{\"d\":\"m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7\"}],[\"$\",\"rect\",\"izxlao\",{\"x\":\"2\",\"y\":\"4\",\"width\":\"20\",\"height\":\"16\",\"rx\":\"2\"}],\"$undefined\"]}],\"sarvesh.angadi1997@gmail.com\"]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-sm font-semibold uppercase tracking-wider text-foreground\",\"children\":\"Social\"}],[\"$\",\"ul\",null,{\"className\":\"mt-2 flex items-center gap-4\",\"children\":[[\"$\",\"li\",\"GitHub\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/SarveshAngadi09\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex h-10 w-10 items-center justify-center rounded-lg border border-border text-muted-foreground transition-colors hover:border-primary/30 hover:text-primary\",\"aria-label\":\"GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}]}],[\"$\",\"li\",\"LinkedIn\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/sarvesh-angadi-067375154/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex h-10 w-10 items-center justify-center rounded-lg border border-border text-muted-foreground transition-colors hover:border-primary/30 hover:text-primary\",\"aria-label\":\"LinkedIn\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}],[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}],\"$undefined\"]}]}]}]]}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"footer\",null,{\"className\":\"border-t border-border px-6 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto flex max-w-5xl flex-col items-center justify-between gap-4 sm:flex-row\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"© 2026 Sarvesh Angadi. All rights reserved.\"}],[\"$\",\"p\",null,{\"className\":\"font-mono text-xs text-muted-foreground/60\",\"children\":\"Latent space\"}]]}]}]\ne:[\"$\",\"script\",\"script-0\",{\"src\":\"/Portfolio/_next/static/chunks/f813fde7a26bc4e5.js\",\"async\":true,\"nonce\":\"$undefined\"}]\nf:[\"$\",\"$L23\",null,{\"children\":[\"$\",\"$24\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@25\"}]}]\n10:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L26\",null,{\"children\":\"$L27\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L28\",null,{\"children\":[\"$\",\"$24\",null,{\"name\":\"Next.Metadata\",\"children\":\"$L29\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"12:[\"$\",\"path\",\"1gqd8o\",{\"d\":\"M17.598 6.5A3 3 0 1 0 12 5a3 3 0 1 0-5.598 1.5\"}]\n13:[\"$\",\"path\",\"iwvgf7\",{\"d\":\"M17.997 5.125a4 4 0 0 1 2.526 5.77\"}]\n14:[\"$\",\"path\",\"efp6ie\",{\"d\":\"M18 18a4 4 0 0 0 2-7.464\"}]\n15:[\"$\",\"path\",\"1gq6am\",{\"d\":\"M19.967 17.483A4 4 0 1 1 12 18a4 4 0 1 1-7.967-.517\"}]\n16:[\"$\",\"path\",\"k1g0md\",{\"d\":\"M6 18a4 4 0 0 1-2-7.464\"}]\n17:[\"$\",\"path\",\"q97ue3\",{\"d\":\"M6.003 5.125a4 4 0 0 0-2.526 5.77\"}]\n18:[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Deep Learning\"}]\n19:[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Designing and training CNNs and transformers for object detection, segmentation, and visual place recognition.\"}]\n1a:[\"$\",\"div\",\"GenAI-Powered 3D Perception\",{\"className\":\"group rounded-xl border border-border bg-card p-6 transition-colors hover:border-primary/30\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 inline-flex h-10 w-10 items-center justify-center rounded-lg bg-primary/10 text-primary\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-box h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"hh9hay\",{\"d\":\"M21 8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16Z\"}],[\"$\",\"path\",\"g66t2b\",{\"d\":\"m3.3 7 8.7 5 8.7-5\"}],[\"$\",\"path\",\"d0xqtd\",{\"d\":\"M12 22V12\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"GenAI-Powered 3D Perception\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Applying generative models and Gaussian Splatting to enable scalable 3D scene reconstruction, immersive mapping, and real-time spatial intelligence for robotics and AR/VR applications.\"}]]}]\n1b:[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}]\n1c:[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}]\n1d:[\"$\",\"p\",null,{\"className\":\"flex-1 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Implementation and analysis of adversarial attack strategies and defense mechanisms to study robustness in deep neural networks.\"}]\n1e:[\"$\",\"div\",null,{\"className\":\"mt-4 flex flex-wrap gap-2\",\"children\":[[\"$\",\"span\",\"Python\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Python\"}],[\"$\",\"span\",\"Pytorch\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Pytorch\"}],[\"$\",\"span\",\"OpenCV\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"OpenCV\"}],[\"$\",\"span\",\"Neural Networks\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Neural Networks\"}]]}]\n"])</script><script>self.__next_f.push([1,"1f:[\"$\",\"article\",\"Mapping facial features and hand gestures\",{\"className\":\"group flex flex-col rounded-xl border border-border bg-card p-6 transition-all hover:border-primary/30 hover:shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 flex items-center justify-between\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-card-foreground\",\"children\":\"Mapping facial features and hand gestures\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/SarveshAngadi09/Face-Hand-Interaction-Computer-vision\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-muted-foreground transition-colors hover:text-primary\",\"aria-label\":\"View Mapping facial features and hand gestures on GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}]]}],[\"$\",\"p\",null,{\"className\":\"flex-1 text-sm leading-relaxed text-muted-foreground\",\"children\":\"Implementation of face and palm detection using mediapipe and openCV\"}],[\"$\",\"div\",null,{\"className\":\"mt-4 flex flex-wrap gap-2\",\"children\":[[\"$\",\"span\",\"Python\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"Python\"}],[\"$\",\"span\",\"mediapipe\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"mediapipe\"}],[\"$\",\"span\",\"OpenCV\",{\"className\":\"rounded-md bg-primary/8 px-2 py-0.5 font-mono text-xs text-primary\",\"children\":\"OpenCV\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"20:[\"$\",\"div\",null,{\"className\":\"mt-10 text-center\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/SarveshAngadi09\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-2 text-sm font-medium text-primary transition-colors hover:text-primary/80\",\"children\":[\"View all projects on GitHub\",[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3.5 w-3.5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}]}]\n21:[\"$\",\"path\",\"1ays0h\",{\"d\":\"M5 12h14\"}]\n22:[\"$\",\"path\",\"xquz4c\",{\"d\":\"m12 5 7 7-7 7\"}]\n"])</script><script>self.__next_f.push([1,"27:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"25:null\n29:[[\"$\",\"title\",\"0\",{\"children\":\"Portfolio | Robotics \u0026 Computer Vision Engineer\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Personal portfolio of a Robotics \u0026 Computer Vision engineer specializing in perception systems, deep learning, and camera calibration.\"}]]\n"])</script></body></html>